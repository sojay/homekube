---

#
# 1. (Required) Cluster details - Cluster represents the Kubernetes cluster layer and any additional customizations
#

# (Optional) Cluster name; affects Cilium and Talos
#   Default is "home-kubernetes"
bootstrap_cluster_name: "home-kubernetes"

# (Required) Generated schematic id from https://factory.talos.dev/
bootstrap_schematic_id: "376567988ad370138ad8b2698212367b8edcb69b5fd68c80be1f2ec7d603b4ba"

# (Required) The CIDR your nodes are on (e.g. 192.168.1.0/24)
bootstrap_node_network: "192.168.0.140/25"

# (Required) Use only 1, 3 or more ODD number of controller nodes, recommended is 3
#   Worker nodes are optional
bootstrap_node_inventory:
    - name: "talos-controlplane"      # (Required) Name of the node (must match [a-z0-9-\]+)
      address: "192.168.0.234"         # (Optional) IP address of the node (Remove if node has a static DHCP reservation)
      controller: true    # (Required) Set to true if this is a controller node
      disk: "/dev/sda"            # (Required) Device path or serial number of the disk for this node (talosctl disks -n <ip> --insecure)
      mac_addr: "bc:24:11:28:33:6a"        # (Required) MAC address of the NIC for this node (talosctl get links -n <ip> --insecure)
    #   schematic_id: ""    # (Optional) Override the 'bootstrap_schematic_id' with a node specific schematic ID from https://factory.talos.dev/
    #   mtu: ""             # (Optional) MTU for the NIC, default is 1500
    #   manifests:          # (Optional) Additional manifests to include after MachineConfig
    #     - extra.yaml      #            Ref: https://www.talos.dev/v1.7/reference/configuration/extensions/extensionserviceconfig/
    #   extension_services: # (Optional) Additional talhelper ExtensionServices (supports talenv.sops.yaml envsubst)
    #     - name: name
    #       configFiles:
    #         - content: |-
    #             ...
    #       mountPath: ...
    #       environment:
    #         - key=value

    # Worker nodes

    - name: "talos-worker01"    # (Required) Name of the node (must match [a-z0-9-\]+)
      address: "192.168.0.235"       # (Optional) IP address of the node (Remove if node has a static DHCP reservation)
      controller: false    # (Required) Set to true if this is a controller node
      disk: "/dev/sda"            # (Required) Device path or serial number of the disk for this node (talosctl disks -n <ip> --insecure)
      mac_addr: "bc:24:11:2c:cb:ee"        # (Required) MAC address of the NIC for this node (talosctl get links -n <ip> --insecure)
      mtu: ""             # (Optional) MTU for the NIC, default is 1500

    - name: "talos-worker02"    # (Required) Name of the node (must match [a-z0-9-\]+)
      address: "192.168.0.236"       # (Optional) IP address of the node (Remove if node has a static DHCP reservation)
      controller: false    # (Required) Set to true if this is a controller node
      disk: "/dev/sda"            # (Required) Device path or serial number of the disk for this node (talosctl disks -n <ip> --insecure)
      mac_addr: "bc:24:11:ae:c3:80"        # (Required) MAC address of the NIC for this node (talosctl get links -n <ip> --insecure)
    # ...


# (Optional) The DNS servers to use for the cluster nodes.
#   Default is pulled from your DHCP server.
# If using a local DNS server make sure it meets the following requirements:
#   1. your nodes can reach it
#   2. it is configured to forward requests to a public DNS server
#   3. you are not force redirecting DNS requests to it - this will break cert generation over DNS01
# If using multiple DNS servers make sure they are setup the same way, there is no
#   guarantee that the first DNS server will always be used for every lookup.
bootstrap_dns_servers: []

# (Optional) The NTP servers to use for the cluster nodes.
#   Default is pulled from your DHCP server.
bootstrap_ntp_servers: []

# (Required) The pod CIDR for the cluster, this must NOT overlap with any
#   existing networks and is usually a /16 (64K IPs).
# If you want to use IPv6 check the advanced flags below and be aware of
# https://github.com/onedr0p/cluster-template/issues/1148
bootstrap_pod_network: "10.69.0.0/16"

# (Required) The service CIDR for the cluster, this must NOT overlap with any
#   existing networks and is usually a /16 (64K IPs).
# If you want to use IPv6 check the advanced flags below and be aware of
# https://github.com/onedr0p/cluster-template/issues/1148
bootstrap_service_network: "10.96.0.0/16"

# (Required) The IP address of the Kube API, choose an available IP in
#   your nodes host network that is NOT being used. This is announced over L2.
bootstrap_controller_vip: "192.168.0.17"

# (Optional) Add additional SANs to the Kube API cert, this is useful
#   if you want to call the Kube API by hostname rather than IP
bootstrap_tls_sans: []

# (Optional) The default gateway for the nodes
#   Default is derrived from bootstrap_node_network (e.g. 192.168.1.1)
bootstrap_node_default_gateway: "192.168.0.1"

# (Optional) Add vlan tag to network master device, leave blank if you tag ports on your switch instead
#   Ref: https://www.talos.dev/latest/advanced/advanced-networking/#vlans
bootstrap_vlan: ""

# (Required) Age Public Key (e.g. age1...)
# 1. Generate a new key with the following command:
#    > task bootstrap:age-keygen
# 2. Copy the PUBLIC key and paste it below
bootstrap_age_pubkey: "age1lcg2c8efnnnmmlq5ftp85v8enwc7adhrm4auqnjfckww76fj6vrs5redm3"

# (Optional) Use cilium BGP control plane when L2 announcements won't traverse VLAN network segments.
#   Needs a BGP capable router setup with the node IPs as peers.
#   Ref: https://docs.cilium.io/en/latest/network/bgp-control-plane/
bootstrap_bgp:
  enabled: false
  # (Optional) If using multiple BGP peers add them here.
  #   Default is .1 derrived from host_network: ['x.x.x.1']
  peers: []
  # (Required) Set the BGP Autonomous System Number for the router(s) and nodes.
  #   If these match, iBGP will be used. If not, eBGP will be used.
  peer_asn: "64512"   # Router(s) AS
  local_asn: "64513"  # Node(s) AS
  peer_port: 179 # BGP Port - default is TCP port 179
  # (Required) The advertised CIDR for the cluster, this must NOT overlap with any
  #   existing networks and is usually a /16 (64K IPs).
  # If you want to use IPv6 check the advanced flags below
  advertised_network: ""

# (Optional) Secureboot and TPM-based disk encryption
bootstrap_secureboot:
  # (Optional) Enable secureboot on UEFI systems. Not supported on x86 platforms in BIOS mode.
  #   Ref: https://www.talos.dev/latest/talos-guides/install/bare-metal-platforms/secureboot
  enabled: false
  # (Optional) Enable TPM-based disk encryption. Requires TPM 2.0
  #   Ref: https://www.talos.dev/v1.6/talos-guides/install/bare-metal-platforms/secureboot/#disk-encryption-with-tpm
  encrypt_disk_with_tpm: false

# (Optional) Change Cilium load balancer mode
#  Default is "dsr" (Direct Server Return)
#  Ref: https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/
bootstrap_loadbalancer_mode: ""

#
# 2. (Required) Flux details - Flux is used to manage the cluster configuration.
#

# (Required) GitHub repository URL
#   For a public repo use the 'https://' URL (e.g. "https://github.com/onedr0p/cluster-template.git")
#   For a private repo use the 'ssh://' URL (e.g. "ssh://git@github.com/onedr0p/cluster-template.git")
#     If using a private repo make sure to following the instructions with the 'bootstrap_github_private_key' option below.
bootstrap_github_address: "https://github.com/sojay/homekube"

# (Required) GitHub repository branch
bootstrap_github_branch: "main"

# (Required) Token for GitHub push-based sync
# 1. Generate a new token with the following command:
#    > openssl rand -hex 16
# 2. Copy the token and paste it below
bootstrap_github_webhook_token: "c783a5ff8f07fd2e22d6f587d8dfe1c3"

# (Optional) Private key for Flux to access the GitHub repository
#   1. Generate a new key with the following command:
#      > ssh-keygen -t ecdsa -b 521 -C "github-deploy-key" -f github-deploy.key -q -P ""
#   2. Make sure to paste public key from "github-deploy.key.pub" into
#      the deploy keys section of your GitHub repository settings.
#   3. Uncomment and paste the private key below
#   4. Optionally set your repository on GitHub to private
# bootstrap_github_private_key: |
#   -----BEGIN OPENSSH PRIVATE KEY-----
#   ...
#   -----END OPENSSH PRIVATE KEY-----

#
# 3. (Optional) Cloudflare details - Cloudflare is used for DNS, TLS certificates and tunneling.
#

bootstrap_cloudflare:
  # (Required) Disable to manually setup and use a different DNS provider - setting this
  #   to false will not deploy a network namespace or the workloads contained within.
  enabled: true
  # (Required) Cloudflare Domain
  domain: "samboxlab.top"
  # (Required) Cloudflare API Token (NOT API Key)
  #   1. Head over to Cloudflare and create a API Token by going to
  #      https://dash.cloudflare.com/profile/api-tokens
  #   2. Under the `API Tokens` section click the blue `Create Token` button.
  #   3. Click the blue `Use template` button for the `Edit zone DNS` template.
  #   4. Name your token something like `home-kubernetes`
  #   5. Under `Permissions`, click `+ Add More` and add each permission below:
  #      `Zone - DNS - Edit`
  #      `Account - Cloudflare Tunnel - Read`
  #   6. Limit the permissions to a specific account and zone resources.
  #   7. Click the blue `Continue to Summary` button and then the blue `Create Token` button.
  #   8. Copy the token and paste it below.
  token: "n_z050gXM3W7R7IIdSZdnwsN-hv4tlc6QCBBIP8A"
  # (Required) Optionals for Cloudflare Acme
  acme:
    # (Required) Any email you want to be associated with the ACME account (used for TLS certs via letsencrypt.org)
    email: "therealsojay+cloudflare@gmail.com"
    # (Required) Use the ACME production server when requesting the wildcard certificate.
    #   By default the ACME staging server is used. This is to prevent being rate-limited.
    #   Update this option to `true` when you have verified the staging certificate
    #   works and then re-run `task configure` and push your changes to Github.
    production: true
  # (Required) Provide LAN access to the cluster ingresses for internal ingress classes
  # The Load balancer IP for internal ingress, choose an available IP
  #   in your nodes host network that is NOT being used. This is announced over L2.
  ingress_vip: "192.168.0.19"
  # (Required) Gateway is used for providing DNS to your cluster on LAN
  # The Load balancer IP for k8s_gateway, choose an available IP
  #   in your nodes host network that is NOT being used. This is announced over L2.
  gateway_vip: "192.168.0.35"
  # (Required) Options for Cloudflare Tunnel
  #   1. Authenticate cloudflared to your domain with the following command:
  #     > cloudflared tunnel login
  #   2. Create the tunnel with the following command:
  #     > cloudflared tunnel create k8s
  tunnel:
    # (Required) Get the Cloudflared Tunnel ID with the following command:
    #   > jq -r .TunnelID ~/.cloudflared/*.json
    id: "a295519d-5256-4731-9ca3-b7800b29e0d3"
    # (Required) Get the Cloudflare Account ID with the following command:
    #   > jq -r .AccountTag ~/.cloudflared/*.json
    account_id: "09e72e58dbc4d51af81200eb95765944"
    # (Required) Get the Cloudflared Tunnel Secret with the following command:
    #   > jq -r .TunnelSecret ~/.cloudflared/*.json
    secret: "XB39vZ5mg6SUeZUTd+d1GhWv+NC8P3yc4wnJqsCsF0U="
    # (Required) Provide WAN access to the cluster ingresses for external ingress classes
    # The Load balancer IP for external ingress, choose an available IP
    #   in your nodes host network that is NOT being used. This is announced over L2.
    ingress_vip: "192.168.0.20"

# (Optional) Feature gates are used to enable experimental features
# bootstrap_feature_gates:
#   # Enable Dual Stack IPv4 first
#   #   IMPORTANT: I am looking for people to help maintain IPv6 support since I cannot test it.
#   #     Ref: https://github.com/onedr0p/cluster-template/discussions/1510
#   #   IMPORTANT: Cilium does not currently support IPv6 L2 announcements.
#   dual_stack_ipv4_first: false
